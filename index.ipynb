{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CAPSTONE PROJECT MENTAL HEALTH ISSUE IDENTIFICATION SYSTEM**\n",
    "\n",
    "Please fill out:\n",
    "* Student names: \n",
    "* Student pace:  **PART TIME**\n",
    "* Scheduled project review date/time: **18/11/2024**\n",
    "* Instructor name: ****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.BUSINESS UNDERSTANDING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.  Introduction**\n",
    "\n",
    "Mental health has become an urgent public health concern across the globe, and Kenya is no exception. Approximately 25% of outpatients and 40% of inpatients in Kenyan healthcare facilities are affected by mental health conditions, according to the Kenyan National Commission of Human Rights. Depression, substance abuse, stress, and anxiety disorders are among the most commonly diagnosed mental health issues in hospital settings, a reflection of an alarming national trend. The situation is compounded by limited data on mental health, neurological issues, and substance use (MNS) in Kenya, making it challenging to address these concerns effectively.\n",
    "\n",
    "\n",
    "The World Health Organization (WHO) ranks Kenya among the African nations with the highest depression rates, with estimates suggesting that around two million Kenyans are impacted by depression alone. Disturbingly, one in four Kenyans will experience a mental health disorder at some point in their lives.\n",
    "\n",
    "\n",
    "Given the urgent need to address mental health concerns, this project aims to leverage artificial intelligence to identify and analyze mental health indicators within social media text.\n",
    "\n",
    "By capturing and analyzing patterns of mental health issues expressed in public discourse, the project seeks to provide insights that can inform policymakers, healthcare providers, and support systems. In doing so, it contributes to a broader understanding of mental health in Kenya and aligns with the national objective of prioritizing mental well-being.\n",
    "\n",
    "**Problem Statement**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mental health issues like depression, anxiety, and suicidal tendencies often go unnoticed in daily conversations, especially in online forums, social media posts, or text-based support systems. Existing tools are either too general or overly reliant on structured input, missing subtle signs of mental distress embedded in unstructured conversations. This project aims to identify potential mental health concerns based on users’ language and conversational patterns in online texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goals and Objectives**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.Identify and Categorize Mental Health Issues:**\n",
    "\n",
    "Develop a model that can accurately classify different mental health issues (e.g., depression, anxiety, suicidal tendencies) based on text data in Reddit posts and comments.\n",
    "\n",
    "**2.Analyze Language Patterns Linked to Mental Distress:**\n",
    "\n",
    " Detect and analyze linguistic features and conversational patterns commonly associated with mental health issues to help distinguish subtle indicators of distress.\n",
    "\n",
    " **3.Assess Sentiment and Emotional Intensity:**\n",
    " \n",
    "  Implement sentiment analysis to assess the emotional intensity and tone of the posts and comments, helping to prioritize urgent cases or severe distress\n",
    "\n",
    "  **4.Provide Actionable Insights for Intervention:**\n",
    "  \n",
    "   Generate insights that could support mental health professionals and social media moderators in identifying and addressing potential cases of mental health crises on forums and social platforms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STAKEHOLDERS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 1.Government and Health Agencies ###\n",
    "\n",
    "i. **Ministry of Health (Kenya)**: As a primary body responsible for public health policies, they are key stakeholders in using the project's insights to shape mental health policies and interventions.\n",
    "\n",
    "ii. **Kenyan National Commission on Human Rights**: Involved in advocacy for better mental health services and safeguarding human rights for those affected by mental health issues.\n",
    "\n",
    "iii. **National Authority for the Campaign Against Alcohol and Drug Abuse (NACADA)**: Given the links between substance abuse and mental health, NACADA's involvement could help tailor intervention programs.\n",
    "\n",
    "### 2.Healthcare Providers ###\n",
    "\n",
    "i. **Psychiatrists, Psychologists, and Therapists**: As frontline workers in diagnosing and treating mental health disorders, they would benefit from insights into prevalent issues and potential trends in patient symptoms.\n",
    "\n",
    "ii. **Healthcare Facilities (Hospitals, Clinics)**: Understanding the mental health landscape can help facilities prepare resources and adapt treatment protocols to better address patient needs.\n",
    "\n",
    "iii. **Public Health Organizations**: Including organizations like the World Health Organization (WHO), which can leverage findings to inform global and regional strategies on mental health.\n",
    "\n",
    " ### 3.Mental Health Advocacy Groups and NGOs ###\n",
    "\n",
    "i. **Basic Needs Kenya, Mental Health Kenya, and Befrienders Kenya**: These advocacy groups work on awareness, support, and outreach programs, so insights from the project can help them tailor their initiatives and better support affected individuals.\n",
    "\n",
    "ii. **Kenya Red Cross**: Often involved in providing mental health support during crises, they could use the data to identify areas with higher mental health needs.\n",
    "\n",
    "### 4.Policy Makers and Legislators ###\n",
    "\n",
    "i. **National Assembly's Health Committee**: To help in reviewing and proposing mental health legislation that aligns with the insights gathered from the analysis.\n",
    "\n",
    "ii. **County Health Administrators**: Local level officials who can use insights for tailored mental health programs at the community level.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.DATA COLLECTION**\n",
    "\n",
    "To gather a robust dataset for the Mindcheck project, we utilized the Reddit API through the Python Reddit API Wrapper (PRAW). This approach enabled us to collect a wide range of posts and comments relevant to mental health discussions, positive expressions, and neutral content, which would support the accurate identification and classification of mental health concerns.\n",
    "\n",
    "we used keyword-based search queries and collected up to 5,000 posts per subreddit. Each post’s title, body, comments, and metadata (e.g., author information, comment scores, timestamps, and subreddit details) were captured to support downstream text analysis. We also included additional post attributes, such as flair, upvote ratios, and crosspost counts, which may serve as helpful features in identifying mental health patterns.\n",
    "\n",
    "The final dataset was structured and saved as a CSV file for convenient access, providing a comprehensive sample of mental health, positive, and neutral content from Reddit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data structure supports a comprehensive analysis of mental health discussions on social media, allowing for insights into engagement, sentiment, and topic categorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATA LOADING AND IMPORTING RELEVANT LIBRARIES**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING RELEVANT LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADING THE DATASET\n",
    "\n",
    "data = pd.read_csv(\"broad_reddit_search_with_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VIEW FIRST FIVE ROWS\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2 DATA DESCRIPTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GETTING GENERAL INFORMATION ON NON-NULL COUNTS AND DATA TYPES FOR PER COLUMN\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description of the data:**\n",
    "\n",
    "Total Entries: 92,395\n",
    "\n",
    "Columns: 27, with various data types including object (text), int64 (integer), float64 (floating-point), and bool (boolean).\n",
    "\n",
    "\n",
    "**Data Columns Overview**\n",
    "\n",
    "**1.Post and Comment Content:**\n",
    "\n",
    "**title:**\n",
    " The title of the post, which may provide a summary of the content.\n",
    "**post_body**\n",
    " The main content or body of the post.\n",
    "\n",
    "**comment_body:** \n",
    "The content of a specific comment on the post.\n",
    "\n",
    "**2.Engagement and Score:**\n",
    "\n",
    "**post_score:** \n",
    "The score or upvotes received by the post, which may indicate popularity.\n",
    "**comment_score:**\n",
    "The score or upvotes received by the comment.\n",
    "**upvote_ratio:**\n",
    "The ratio of upvotes to total votes for the post.\n",
    "**number of_crossposts:**\n",
    "The number of times this post has been cross-posted to other subreddits.\n",
    "**post_num_comments:** \n",
    "The number of comments on the post, indicating engagement.\n",
    "\n",
    "**3.Metadata:**\n",
    "\n",
    "**post_url:** The URL of the post, useful for tracking or referencing.\n",
    "**created:** The timestamp when the post or comment was created.\n",
    "**subreddit:** The subreddit where the post or comment was made, which helps in filtering data by community focus.\n",
    "**label:** This could represent a manual or model-assigned label (e.g., sentiment, topic, or mental health category).\n",
    "\n",
    "**4.User Information:**\n",
    "**author:** The username of the post’s author.\n",
    "**comment_author:** The username of the comment’s author.\n",
    "**author_premium:** Indicates if the author has a premium account.\n",
    "**distinguished:** A flag indicating if the post is from a moderator or other special status.\n",
    "\n",
    "\n",
    "**5.Post and Comment Attributes:**\n",
    "\n",
    "**over_18:** A flag indicating if the content is marked as NSFW (Not Safe For Work).\n",
    "is_self_post: Indicates if the post is a self-post (text-only) rather than a link.\n",
    "**post_flair and link_flair_text:** Text tags applied to the post, which may reflect topic categories or sentiments.\n",
    "**author_flair_text:** A flair assigned to the author, possibly indicating affiliation or status in the subreddit.\n",
    "\n",
    "**6.Awards and Other Engagement Indicators:**\n",
    "\n",
    "**all_awardings and total_awards_received** Data on awards given to the post or comment, reflecting user appreciation.\n",
    "**post_thumbnail:** A thumbnail image associated with the post, if available.\n",
    "\n",
    "**7.Identifiers:**\n",
    "post_id and comment_id: Unique identifiers for each post and comment, respectively. These help in tracking specific posts or comments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GETTING GENERAL INFORMATION ON NON-NULL COUNTS AND DATA TYPES FOR PER COLUMN\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK NUMBER OF ROWS AND COLUMNS\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set has 92395 rowns and 27 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DROPPING IRRELEVANT COLUMNS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our project goal of identifying and understanding mental health discussions in social media text:We gruoped the columns into Relevant and Irrelevant columns:\n",
    "\n",
    "**Relevant Columns(11)**\n",
    "\n",
    "**Text Content:** title, post_body, comment_body - Primary text fields for analyzing mental health topics and sentiment.\n",
    "\n",
    "**Engagement Metrics:** post_score, comment_score, upvote_ratio - Indicate community engagement and post relevance.\n",
    "\n",
    "**Categorization:** label, subreddit, post_flair, link_flair_text - Useful for identifying mental health categories, topics, or sentiment.\n",
    "\n",
    "**Timestamp:** created - Helps in analyzing trends over time.\n",
    "\n",
    "**Less Relevant Columns(16)**\n",
    "\n",
    "**Identifiers and URLs:** post_url, post_id, comment_id, author, comment_author - Useful for tracking but not for text analysis.\n",
    "\n",
    "**Other Metadata:** over_18, is_self_post, author premium,distinguished, post_thumbnail, all_awardings, total_awards_received, author_flair_text - Provide limited insight into mental health content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping Columns\n",
    "# List of columns to drop  based on our analysis\n",
    "columns_to_drop = [\n",
    "    'post_url', 'post_id', 'comment_id', 'author', 'comment_author',\n",
    "    'post_num_comments', 'over_18','author_premium','is_self_post', 'distinguished',\n",
    "    'post_thumbnail', 'all_awardings', 'total_awards_received',\n",
    "    'author_flair_text', 'num_crossposts', 'all_awardings'\n",
    "]\n",
    "\n",
    "# Dropping irrelevant columns from the DataFrame\n",
    "data = data.drop(columns=columns_to_drop)\n",
    "\n",
    "# Display the DataFrame to verify\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3 DATA CLEANING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING FOR MISSING VALUES\n",
    "missing_values = data.isnull().sum()\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in 'post_body' with an empty string because it's a text field, \n",
    "# and missing text can be assumed to have no content.\n",
    "data['post_body'] = data['post_body'].fillna('')\n",
    "\n",
    "# Fill missing values in 'post_flair' and 'link_flair_text' with 'No Flair' \n",
    "# or 'Unknown' since flairs are categorical and a missing value here likely means \n",
    "# that the post didn't have any flair assigned.\n",
    "data['post_flair'] = data['post_flair'].fillna('No Flair')\n",
    "data['link_flair_text'] = data['link_flair_text'].fillna('No Flair')\n",
    "\n",
    "# Display the result to verify the filling of missing values\n",
    "data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK FOR DUPLICATES\n",
    "\n",
    "duplicates = data.duplicated()\n",
    "duplicate_count = duplicates.sum()\n",
    "duplicate_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows based on all columns\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "# Reset the index after dropping duplicates\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "# Display the number of rows after removing duplicates\n",
    "print(f\"Number of rows after removing duplicates: {len(data)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DEALING WITH OUTLIERS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to plot histograms and box plots to understand the distribution of the data so that we can choose effective method to deal with outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizng distribution of our data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Select numeric columns only\n",
    "numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Set up the plotting area\n",
    "plt.figure(figsize=(15, len(numeric_columns) * 4))\n",
    "\n",
    "for i, column in enumerate(numeric_columns, 1):\n",
    "    plt.subplot(len(numeric_columns), 2, 2*i - 1)\n",
    "    sns.histplot(data[column], kde=True)\n",
    "    plt.title(f'Histogram of {column}')\n",
    "    \n",
    "    plt.subplot(len(numeric_columns), 2, 2*i)\n",
    "    sns.boxplot(x=data[column])\n",
    "    plt.title(f'Boxplot of {column}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the histograms and boxplots , the data appears to be heavily skewed . Here’s a breakdown of the observations:\n",
    "\n",
    "**Histograms:**\n",
    "\n",
    "Most histograms show a right (positive) skew, with a concentration of values on the left and a long tail extending to the right.\n",
    "This pattern suggests that there are many lower values and a few extreme higher values, which is common in social media engagement metrics like scores and upvote ratios.\n",
    "\n",
    "**Boxplots:**\n",
    "\n",
    "The boxplots show many outliers on the right side, which is a characteristic of positively skewed data.\n",
    "The interquartile range (IQR) is narrow for several columns, but there are many data points beyond the upper whisker, indicating the presence of high-value outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numeric columns in the DataFrame\n",
    "numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Initialize a dictionary to store outliers\n",
    "iqr_outliers = {}\n",
    "\n",
    "for column in numeric_columns:\n",
    "    # Calculate Q1 (25th percentile) and Q3 (75th percentile) for each column\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1  # Calculate the IQR\n",
    "\n",
    "    # Define outlier boundaries\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Identify outliers\n",
    "    outliers = data[column][(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "    iqr_outliers[column] = outliers\n",
    "\n",
    "    # Print the number of outliers for each column\n",
    "    print(f\"{column}: {len(outliers)} outliers\")\n",
    "\n",
    "# Optional: Display specific outlier values for a particular column\n",
    "# Uncomment and replace 'column_name' with the name of the column to inspect\n",
    "# print(iqr_outliers['column_name'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the nature and purpose of our analysis, removing these outliers may lead to a loss of valuable information about high-engagement or high-impact posts. We decided to retain them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate percentile rank of each value in a column\n",
    "def calculate_percentile_ranks(outliers, column):\n",
    "    # Calculate the percentile rank for each outlier value\n",
    "    percentile_ranks = [np.percentile(data[column], (data[column] <= val).mean() * 100) for val in outliers]\n",
    "    return percentile_ranks\n",
    "\n",
    "# Initialize dictionary to store percentile ranks of outliers for each column\n",
    "outlier_percentiles = {}\n",
    "\n",
    "# List of numeric columns to check\n",
    "columns_to_check = ['comment_score', 'post_score', 'upvote_ratio']\n",
    "\n",
    "# Detect outliers and calculate their percentile ranks\n",
    "for column in columns_to_check:\n",
    "    # Calculate Q1 and Q3 for the IQR method\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Define outlier boundaries\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Identify outliers\n",
    "    outliers = data[column][(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "    \n",
    "    # Calculate the percentile ranks of the outliers\n",
    "    percentile_ranks = calculate_percentile_ranks(outliers, column)\n",
    "    \n",
    "    # Store results in a dictionary\n",
    "    outlier_percentiles[column] = percentile_ranks\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"{column}: Most outliers fall in the following percentile ranges:\")\n",
    "    print(pd.Series(percentile_ranks).describe())  # Summary statistics of outlier percentiles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis of Outlier Percentiles**\n",
    "\n",
    "**comment_score:**\n",
    "\n",
    "Mean Percentile: 74.98, suggesting that most outliers are relatively high values.\n",
    "Percentiles Range: There’s a wide range with values going as low as the 5th percentile but with a mean around the 75th percentile.\n",
    "\n",
    "**Recommendation:** Cap at the 95th percentile on the upper end. Since there are also some low outliers, we capped the lower end at the 5th percentile.\n",
    "\n",
    "**post_score:**\n",
    "\n",
    "Mean Percentile: 28,390, suggesting that most outliers have very high values.\n",
    "Range: Outliers vary significantly, with many extreme values, as indicated by a high std (25,245).\n",
    "\n",
    "**Recommendation:** Cap the upper end at the 90th or 95th percentile. Given the wide range of values, capping the lower end may not be necessary if the focus is on reducing high extremes.\n",
    "\n",
    "**upvote_ratio:**\n",
    "\n",
    "Mean Percentile: 0.43, with values clustered around 0.34–0.54.\n",
    "Range: Since this is a ratio, outliers are not as extreme as in comment_score or post_score.\n",
    "\n",
    "**Recommendation:** Cap the upper end at the 90th percentile. This should reduce outliers without affecting the main distribution too much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CAPPING OUTLERS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply capping based on the recommended percentiles\n",
    "data['comment_score'] = data['comment_score'].clip(lower=data['comment_score'].quantile(0.05),\n",
    "                                                   upper=data['comment_score'].quantile(0.95))\n",
    "\n",
    "data['post_score'] = data['post_score'].clip(upper=data['post_score'].quantile(0.95))\n",
    "\n",
    "data['upvote_ratio'] = data['upvote_ratio'].clip(upper=data['upvote_ratio'].quantile(0.90))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of capped columns to check for remaining outliers\n",
    "columns_to_check = ['comment_score', 'post_score', 'upvote_ratio']\n",
    "\n",
    "print(\"Outliers detected using IQR method after capping:\")\n",
    "\n",
    "for column in columns_to_check:\n",
    "    # Calculate Q1 and Q3 for the IQR method\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Define outlier boundaries\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Identify outliers\n",
    "    outliers = data[column][(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "    \n",
    "    # Print the number of remaining outliers for each column after capping\n",
    "    print(f\"{column}: {len(outliers)} remaining outliers after capping\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.0 EXPLORATORY DATA ANALYSIS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1 Bar Plot showing Distribution of Labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot the distribution of labels\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=data, x='label')\n",
    "plt.title(\"Distribution of Mental Health Labels\")\n",
    "plt.xlabel(\"Mental Health Issue Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights:**\n",
    "\n",
    " The chart shows three categories with varying frequencies. Neutral category (the green bar) has the highest count, followed by the happy/positive category (orange bar), and the lowest is the  mental health issue category (blue bar).\n",
    "\n",
    "\n",
    "**Implications**\n",
    "\n",
    "some categories are more prevalent in the  dataset e.g Neutral and happy . This could impact model training, as an imbalanced dataset may lead the model to perform better on the majority category and worse on the minority.\n",
    "\n",
    "We may need to consider balancing techniques, such as oversampling the minority class or using class weights, to ensure that the model performs well across all categories.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2 Histogram showing Post Length Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the length of each post\n",
    "data['post_length'] = data['post_body'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Plot the distribution of post lengths\n",
    "plt.figure(figsize=(15, 12))\n",
    "sns.histplot(data['post_length'], bins=30, kde=True)\n",
    "plt.title(\"Distribution of Post Lengths\")\n",
    "plt.xlabel(\"Post Length (words)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "\n",
    "The data is highly skewed to the right, with a large concentration of posts on the left side (lower range).\n",
    " This indicates that most posts fall within a lower range  i.e they are shorter than 1000 words , while fewer posts have higher values above 1000 words.\n",
    "\n",
    " However, there are some outliers that deviate from the majority  post length and may go up of up to 6,000 words.\n",
    "\n",
    " **Implications**\n",
    "\n",
    " For modeling, we may handle outliers (very long posts) separately or exclude them if they don't contribute meaningfully to our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.3 Histrogram Showing Distribution of Sentiment Scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Apply VADER sentiment analysis to each post\n",
    "data['sentiment'] = data['post_body'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
    "\n",
    "# Plot the sentiment distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data['sentiment'], bins=30, kde=True)\n",
    "plt.title(\"Distribution of Sentiment Scores\")\n",
    "plt.xlabel(\"Sentiment Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implications**\n",
    "\n",
    "Thie Histogram seems to show a bimodal distribution with two distinct peaks.\n",
    "\n",
    "The two prominent peaks indicate that there are two distinct groups within the data. This could imply two different populations or behaviors within the dataset.\n",
    "\n",
    "The first peak represents one group whose sentiment score is centered around  -0.25 (fairly negative)  while the second peak represents a differenet  group whose sentiment score is centered around 1(very postive).\n",
    "\n",
    "Both ends of the histogram show smaller bars, which could represent outliers or infrequent behaviors not fitting into the main clusters.\n",
    "\n",
    "**Implications**\n",
    "\n",
    "Given the clear separation between the two peaks, it may be beneficial to treat the two groups separately in our analysis.\n",
    "\n",
    "This segmentation could allow for more targeted insights or better model performance, especially if the behaviors or language used in each group differ.\n",
    "\n",
    "\n",
    "Modeling Considerations:\n",
    "\n",
    "A single model may not capture the nuances across both clusters effectively. We may need to consider building separate models or using clustering techniques to handle each group independently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FEATURE ENGINEERING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to Create a Feature named  High Engagement which shows high-engagement posts based on post_score and visualize with a count plot. . High engagement posts might indicate popular or impactful discussions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Define high engagement based on the 90th percentile of post_score\n",
    "high_engagement_threshold = data['post_score'].quantile(0.90)\n",
    "data['high_engagement'] = data['post_score'] > high_engagement_threshold\n",
    "\n",
    "# Step 2: Filter data for the specific labels: mental_health_issue, happy, and neutral\n",
    "filtered_data = data[data['label'].isin(['mental_health_issue', 'happy', 'neutral'])]\n",
    "\n",
    "# Step 3: Plot high vs low engagement for each label\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='label', hue='high_engagement', data=filtered_data)\n",
    "plt.title('Comparison of High vs. Low Engagement for mental_health_issue, happy, and neutral Labels')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Number of Posts')\n",
    "plt.legend(title='Engagement Level', labels=['Low Engagement', 'High Engagement'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "\n",
    "**Engagement Distribution:**\n",
    "\n",
    "1.Neutral content has the highest number of low-engagement posts (blue), indicating that neutral topics generally receive less interaction from the audience.\n",
    "\n",
    "2.Mental health-related content shows doesn't have any hign engagement posts indicating that people with mental health issues most likely don't want to talk about it on social platform hence the high number posts with  low engagement .\n",
    "\n",
    "3.The Happy label has both  moderate number of both high and low engagement posts, indicating a balanced engagement level for positive content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#viewing columns\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CO-ORELATION MATRIX FOR NUMERICAL FEATURES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Select only numerical columns for the correlation matrix\n",
    "numerical_columns = [\n",
    "    'comment_score', 'created', 'post_score', 'post_created', \n",
    "    'upvote_ratio', 'post_length', 'high_engagement'\n",
    "]\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = data[numerical_columns].corr()\n",
    "\n",
    "# Plot the correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix of Engagement-Related Features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the strong correlation between post_score and high engagement, we'll consider removing one of these columns to reduce multicollinearity.\n",
    "\n",
    "Well keep oneof them   based on the importance to your analysis. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WORD CLOUD VISUALIZATIONS PER LABEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "\n",
    "# Define path to a TrueType font\n",
    "font_path = font_manager.findSystemFonts(fontpaths=None, fontext='ttf')[0]\n",
    "\n",
    "# Function to generate word cloud for a specific label\n",
    "def generate_word_cloud(data, label, column='post_body'):\n",
    "    # Filter the data for the specified label and join all text in the column\n",
    "    text = \" \".join(data[data['label'] == label][column].dropna())\n",
    "    \n",
    "    # Generate word cloud\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='viridis', font_path=font_path).generate(text)\n",
    "    \n",
    "    # Plot word cloud\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Word Cloud for {label} Label')\n",
    "    plt.show()\n",
    "\n",
    "# Generate word clouds for each label\n",
    "generate_word_cloud(data, 'mental_health_issue')\n",
    "generate_word_cloud(data, 'happy')\n",
    "generate_word_cloud(data, 'neutral')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
